{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf36277d",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The TextChunker processes parsed documents into semantic chunks:\n",
    "- Token-based splitting with configurable overlap\n",
    "- Respects section boundaries\n",
    "- Extracts demo files and image metadata\n",
    "- Recursive section hierarchy processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781fc6a4",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed015c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "import re\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    \"\"\"Represents a semantic chunk of content.\"\"\"\n",
    "    component: str\n",
    "    section_title: Optional[str]\n",
    "    section_path: Optional[str]\n",
    "    content: str\n",
    "    demo_files: List[str]\n",
    "    images: List[str]\n",
    "    token_count: int\n",
    "\n",
    "\n",
    "class TextChunker:\n",
    "    \"\"\"Semantic text chunking based on document sections.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_chunk_tokens: int = 512, overlap_tokens: int = 50):\n",
    "        \"\"\"\n",
    "        Initialize chunker.\n",
    "        \n",
    "        Args:\n",
    "            max_chunk_tokens: Maximum tokens per chunk\n",
    "            overlap_tokens: Token overlap between chunks\n",
    "        \"\"\"\n",
    "        self.max_chunk_tokens = max_chunk_tokens\n",
    "        self.overlap_tokens = overlap_tokens\n",
    "    \n",
    "    def estimate_tokens(self, text: str) -> int:\n",
    "        \"\"\"\n",
    "        Estimate token count using 4 characters per token.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to count tokens for\n",
    "        \n",
    "        Returns:\n",
    "            Estimated token count\n",
    "        \"\"\"\n",
    "        return max(1, len(text) // 4)\n",
    "    \n",
    "    def chunk_document(self, document: dict) -> List[Chunk]:\n",
    "        \"\"\"\n",
    "        Chunk a single parsed document.\n",
    "        \n",
    "        Args:\n",
    "            document: Document dict from generate_ast.ts output\n",
    "        \n",
    "        Returns:\n",
    "            List of Chunk objects\n",
    "        \"\"\"\n",
    "        # Handle both old and new formats\n",
    "        component = document.get(\"component\") or document.get(\"name\", \"unknown\")\n",
    "        chunks = []\n",
    "        \n",
    "        sections = document.get(\"sections\", [])\n",
    "        self._process_sections(component, sections, chunks)\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def _process_sections(\n",
    "        self,\n",
    "        component: str,\n",
    "        sections: list,\n",
    "        chunks: List[Chunk],\n",
    "        parent_path: str = \"\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Recursively process sections and create chunks.\n",
    "        \n",
    "        Args:\n",
    "            component: Component name\n",
    "            sections: List of section dicts\n",
    "            chunks: List to accumulate chunks\n",
    "            parent_path: Path to parent section for building hierarchy\n",
    "        \"\"\"\n",
    "        for section in sections:\n",
    "            if isinstance(section, str):\n",
    "                continue\n",
    "            \n",
    "            section_title = section.get(\"title\", \"\")\n",
    "            section_path = f\"{parent_path} > {section_title}\".strip(\"> \")\n",
    "            \n",
    "            # Gather content and metadata\n",
    "            content_parts = []\n",
    "            demo_files = []\n",
    "            images = []\n",
    "            \n",
    "            # Add main content\n",
    "            if content := section.get(\"content\"):\n",
    "                if isinstance(content, str):\n",
    "                    content_parts.append(content)\n",
    "                elif isinstance(content, list):\n",
    "                    for item in content:\n",
    "                        if isinstance(item, str):\n",
    "                            content_parts.append(item)\n",
    "                        elif isinstance(item, dict):\n",
    "                            if item.get(\"type\") == \"paragraph\":\n",
    "                                content_parts.append(item.get(\"text\", \"\"))\n",
    "                            elif item.get(\"type\") == \"demo\":\n",
    "                                if demo_file := item.get(\"file\"):\n",
    "                                    demo_files.append(demo_file)\n",
    "                            elif item.get(\"type\") == \"image\":\n",
    "                                if image_path := item.get(\"src\"):\n",
    "                                    images.append(image_path)\n",
    "            \n",
    "            # Add demo file references\n",
    "            if demos := section.get(\"demos\"):\n",
    "                if isinstance(demos, list):\n",
    "                    for demo in demos:\n",
    "                        if isinstance(demo, dict) and (file := demo.get(\"file\")):\n",
    "                            demo_files.append(file)\n",
    "            \n",
    "            # Add image references\n",
    "            if img_list := section.get(\"images\"):\n",
    "                if isinstance(img_list, list):\n",
    "                    for img in img_list:\n",
    "                        if isinstance(img, dict) and (src := img.get(\"src\")):\n",
    "                            images.append(src)\n",
    "            \n",
    "            # Combine content\n",
    "            combined_content = \" \".join(str(p) for p in content_parts).strip()\n",
    "            \n",
    "            # Create chunk if has content\n",
    "            if combined_content:\n",
    "                token_count = self.estimate_tokens(combined_content)\n",
    "                chunks.append(Chunk(\n",
    "                    component=component,\n",
    "                    section_title=section_title,\n",
    "                    section_path=section_path,\n",
    "                    content=combined_content,\n",
    "                    demo_files=demo_files,\n",
    "                    images=images,\n",
    "                    token_count=token_count\n",
    "                ))\n",
    "            \n",
    "            # Process children (new format) or subsections (old format)\n",
    "            if children := section.get(\"children\"):\n",
    "                self._process_sections(\n",
    "                    component,\n",
    "                    children,\n",
    "                    chunks,\n",
    "                    section_path\n",
    "                )\n",
    "            elif subsections := section.get(\"subsections\"):\n",
    "                self._process_sections(\n",
    "                    component,\n",
    "                    subsections,\n",
    "                    chunks,\n",
    "                    section_path\n",
    "                )\n",
    "    \n",
    "    def chunk_documents(self, documents: List[dict]) -> List[Chunk]:\n",
    "        \"\"\"\n",
    "        Chunk multiple documents.\n",
    "        \n",
    "        Args:\n",
    "            documents: List of document dicts\n",
    "        \n",
    "        Returns:\n",
    "            Combined list of chunks from all documents\n",
    "        \"\"\"\n",
    "        all_chunks = []\n",
    "        for doc in documents:\n",
    "            all_chunks.extend(self.chunk_document(doc))\n",
    "        return all_chunks\n",
    "\n",
    "\n",
    "print(\"TextChunker module loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0925cd69",
   "metadata": {},
   "source": [
    "## Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example document structure (from generate_ast.ts output)\n",
    "example_doc = {\n",
    "    \"name\": \"Button\",\n",
    "    \"description\": \"A clickable button component\",\n",
    "    \"sections\": [\n",
    "        {\n",
    "            \"title\": \"Usage\",\n",
    "            \"description\": \"How to use the Button component\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"paragraph\", \"text\": \"The Button component is a fundamental UI element.\"},\n",
    "                {\"type\": \"demo\", \"file\": \"button-demo.tsx\", \"description\": \"Basic button example\"},\n",
    "                {\"type\": \"image\", \"src\": \"button.png\"}\n",
    "            ],\n",
    "            \"subsections\": [\n",
    "                {\n",
    "                    \"title\": \"States\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"paragraph\", \"text\": \"Buttons can have multiple states like disabled, loading, etc.\"}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create chunker and process\n",
    "chunker = TextChunker(max_chunk_tokens=512, overlap_tokens=50)\n",
    "chunks = chunker.chunk_document(example_doc)\n",
    "\n",
    "# Display results\n",
    "print(f\"Created {len(chunks)} chunks:\\n\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"Chunk {i}:\")\n",
    "    print(f\"  Component: {chunk.component}\")\n",
    "    print(f\"  Section: {chunk.section_path}\")\n",
    "    print(f\"  Tokens: {chunk.token_count}\")\n",
    "    print(f\"  Demos: {chunk.demo_files}\")\n",
    "    print(f\"  Content preview: {chunk.content[:80]}...\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
